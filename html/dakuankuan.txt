1:postgresql也很强大，为何在中国大陆，mysql成为主流，postgresql屈居二线呢？
以下均为个人感觉，没做过统计，就当个参考吧。
mysql和postgres的早期完全是两个极端。mysql更像是个“基本上满足关系数据库语法的大号KV”，对关系型数据库的高级功能支持的很不好。我入行时接触的MySQL 5.1和MyISAM存储引擎，不支持ACID，但有如下几点在当时的互联网公司看来是非常合适：
反过来再看postgres的优点，会发现对于OLTP并没有太大的吸引力：
因此早期mysql变成了事实上的互联网企业OLTP的事实标准。不管干啥业务，mysql都不可或缺。在行业里跳槽来跳槽去的程序员普遍对mysql也更熟悉。大量围绕mysql的商业服务都成为了行业主流。新一代分布式数据库，像TiDB为了吸引用户，首先要做的是“兼容mysql的语法”。
再往后，mysql增加了更多“关系型数据库该有的”功能，比如完全支持ACID的innodb成为默认存储引擎，比如5.7的json原生支持，8.0的window function/CTE。而postgres也增加了更多的“互联网功能”。但是时机已经过去了。大家mysql跑着业务好好的。而切换数据库绝对不是仅仅像某些ORM标榜的换一个Dialect就行的。而是整个编程模型，性能表现，运维工具和流程都要有巨大的变化。如非必要，犯不着为了一个“most advanced"的标语去折腾，更不会为了数据库爱好者的情怀做伤害利益的事情。

2:如何看待王垠对数据库的理解？
看了一遍王垠的文章，觉得很是有趣，也顺便白话白话吧。
我同意这篇文章的很多观点，比如：
但是这篇文章最大的问题就是
，但完全无视关系型数据库和SQL这么多年来对整个计算机科学和工程领域的巨大影响和作用，
。
现在但凡是写个需要存储的程序基本上都要某种数据库，而且极大概率是“关系型数据库“。如果真如王垠所说，SQL和关系型数据库如此的不堪，就等价于承认所有SQL/关系型数据库的使用者都是傻X。为什么在关系型数据库从学术到商用长达几十年的历史上没有一个人比王垠更聪明，发现这个问题，并去解决它？虽然理论上的确有这个可能性，但是从直觉上看，这种情况发生的概率又有多少呢？
如果照他的思路推广，那么汽车就就不是我们现在看到的样子：不需要ESP和转向助力，直接控制轮子转向是最好的，况且ESP也无法“智能”的判断开车的人是想转向躲开障碍物，还是就是想玩漂移；不需要ABS和EBS，直接人来控制硬刹车是最好的；不需要自动挡，因为高手操控手动挡既省油，又能更快的加速；不需要车的外壳，因为车的本质就是4个轮子+发动机，本质上就是用来跑的；至于那些反光镜、雨刷、天窗、收音机、导航、空调、舒适的皮质座椅……，更加都是浮云，LOW的不值一提。
我觉得王垠的这篇和其他很多篇都有同样的问题，就是
只强调某个特定角度（大概率是他熟悉的领域）的优势，而不管“易用性”、“成本”、“兼容性”、“抽象约定“、“优化空间”、“可运维性“……等等一系列现实中必须考虑的问题，甚至
。换句话说，他拿着一个锤子（应该承认，是个大锤子），看哪里都是钉子。
那么为什么SQL和关系型数据库可以长期占据统治性地位呢？我不是这个领域的专家，只从我看到的一些参考资料上简单说说。希望有专家帮助补充。
先从存储说起。王垠的文章中提到了struct会比关系型灵活的多。struct里可以有指针任意的指、可以任意嵌套。而关系型说白了就是一个大数组。问题是，struct的强大能力只有在可以很容易随机访问的内存里才能实现，而数据库一开始就要处理数据量远超内存的场景。数据库必须解决外存（早期主要是硬盘）的问题。硬盘因为要物理旋转，需要按照“簇”的方式访问，所以像struct那种指来指去的方法到了外存上基本上就会把性能表现降低数个数量级。上过计算机课的人都知道有些数据结构和算法适合内存，而有些适合外存（比如BTree）。关系型数据库最终选择了BTree。这就要求整个数据的结构必须大致得是“一行行”的，放在树的节点；树的结构本身用来做查询的优化。
因为整个数据的存储形式形成了BTree，整个查询的优化就可以围绕BTree来做。假如用struct，因为是任意的，所以就无法做优化。只有开发人员自己才知道数据结构，才知道怎么使用。比如丢给你个指针做入口，查找某个可能触达的数据，不知道内部结构的情况下，能做的也就是深度优先和广度优先去扫。
有些数据结构可以帮忙，比如常用的hash，list，stack，skiplist……。开发者可以用它们来优化自己的查询。就算是外存的相关逻辑，也可以抽象出来，用某种lib来做。问题是，这么做对于稍微复杂一点的场景，就会
。你能体会到一个业务程序员在思考者各种折扣和返券的时候，还得考虑哪个数据存内存，哪个存到磁盘的哪个簇，然后再做查询优化的心情吗？这里还没提隔离的问题、原子性的问题、锁的问题、磁盘刷盘的问题……。没有靠谱数据库的支持，根本就无法在合理的时间deliver可用的代码，程序员需要同时花大精力和机器与PM双线作战。并不是每个人都是计算机科学的编码高手，熟悉算法、数据结构和存储，以及业务逻辑，都能在两边游刃有余。并不是每家公司都能雇佣多个像王垠这样的做编译的高级工程师写数据库的访问程序。
出现一个靠谱的、通用的数据库的前提必然是数据访问提供一个抽象和一套接口。而这个接口从使用者的角度，必然
，绝对不可能暴露底层的实现细节（比如对MyISAM表插入一条记录会加个表锁，而对InnoDB插就是另外一套基于MVCC的逻辑）。也许SQL并不一定是个完美的接口，但是是经过多少年的用户和数据库厂商磨合的结果。这个结果甚至逼迫着得很多现代非关系型数据库、分布式数据库必须提供类似于SQL的部分语法支持。有了SQL和关系型数据库，大量不那么熟悉数据结构、查询优化、存储的开发者可以加入到开发的队伍中，构建起大量的信息系统。整个产业就在这个过程中极大的发展。
在整个行业发展过程中，一些需求催生了各种各样的的优化的机会。有人抓住机会去提出新的数据模型和查询接口。比如：
就连SQL自己也在演进，比如各大数据库增加了对json格式的支持，MySQL还搞了个X-API，弄得像mongo一样；Postgres中一列可以是复合的类型（类似于struct），也可以是数组类型。mysql和postgres还支持全文索引（按照王垠的讲法，是不是这时候得先用一套LSM tree库玩转sstable管理，然后再攒一个lucene做分词和倒排？）
根据实际需求，从上面这些备选中，总能找到几个东西组合在一起满足需要。如果还不够用，那就按照需求定制，就像polarDB，TiDB。但我相信，绝大部分的开发场景，弄个mysql，sqlite之类的就完事了，不需要特别仔细的优化。
遇到了SQL处理不了的，有价值的问题，去解决，去优化，去建模就好。光吐槽SQL这也不行，那也不行，没有任何卵用。
———
晚上迷迷糊糊写的，早上一看这么多赞。感谢支持。其实只是白话，不如这个问题下其他答案干货，推荐大家多阅读存储从业者的回答，可以学到更实在的东西。
之前我对王垠的印象还停留在很多年前他评价操作系统的时候，看到本题就去走读了他最近的blog。很多观点我都认同，也能学到一些东西，但不知道为啥他的很多文章一到推导结论时就会莫名跑偏。所以看看就好吧。我不会再写评论他文章的文了，DONOT REPEAT YOURSELF：-）
____
突然发现这篇文章是2014年的。不知为何这两天推到我时间线上了。如果垠神现在不这样了，那就当我在这里犯个傻吧～

3:为什么技术主管跟我说程序员学算法不是最重要的，从工作项目中学习实际才是最重要的？
感谢你的领导吧。
你在公司里工作，也就意味着你的工作目标是“用技术做工程，实现产品/服务的需求，并保证质量“。你要解决的问题一开始就不是算法这么单纯的东西。算法肯定是有用的，但是在你目前所处的环境下，算法也许只是占比很少的一个组成部分，更多的部分是其他技术或者非技术问题的处理方式。比如：
算法能够解决其中一部分问题，但更多的是跟算法没啥关系的问题。喜欢算法，追求技术极致没有错，但是一个要点是要搞清楚：
。
只要自己的工作还是工程师，而不是“钻研算法”，那就要承认必须接受现实的复杂性，也要接受解决问题策略和工具的多样性。认清这个事实，才能打好把事情做成的基础（包括提高算法能力）。
-----
感谢这么多赞。为此，我抛开原题目，就着个人成长的问题多说两句。
不管是做哪个行业的人，非常重要的一件事是【成长】。一旦你发现每天按部就班的做事情，哪怕做得很好，也要开始警觉起来：为什么每天事情都是一样的，重复的？为什么自己没有处理更重要的事情，价值更大的事情呢？是合作者（领导、同事、投资人、合伙人……）不相信自己吗？
如果是这样，那么为什么周围的人不愿意和你就着更重要、更有价值的事情展开合作呢？是不是自己什么地方有问题呢？是否是自己对于具体的问题的决策质量不够高，或者不够有效率呢？（小到怎么组织一段代码，大到决定组织架构和资源分配）。又或者价值观完全不相符？
能力不足的话，要做出改变。花精力去学习，提高，不断的总结和改善自己的决策能力。静下心来坦诚的面对自己的缺陷——那些缺陷不是别人的问题，不是公司的问题，也不是社会的问题。这个世界的确并不公平，但并不欠你什么。
比如你深深的相信算法是你改变命运的关键技能，也是个人兴趣所在，那么抓紧一切时间去提升算法能力是非常正确的。只不过：
1）要保证完成工作任务，因为工作这个契约是指公司出薪水，你出活。公司不是大学。签了合同起码的职业素养要有。如果你不喜欢这个工作，就不应该继续在这里呆着。又或者短期内没法找到符合自己理想的工作，那么先找一个猫着，然后慢慢找。过个3～5年，总不能说还找不到吧？
2）如果几年后发现算法帮助你的提升空间有限，要不是因为自己并不能够深入进去，在算法领域无法作出卓越的贡献；要不是自己所处的行业算法并不是核心的问题。不管哪种，不要后悔和灰心，而是复盘和总结，到底什么是自己能做的更加优秀的？自己选的方向到底对不对呢？这也就是为什么要【从实际出发】，只有面对现实才能抓到机会。空想一个问题，而不验证是否真的是“问题”，只会吃瘪而已。
3）你依靠算法获取巨大收益的唯一条件是：你比周围的人在算法这个领域懂的多得多，并且利用这个认知的差异解决了很有价值的问题。这两条有信心做到吗？而且，类似的，我也可以说，一个人比周围人对金融运作的认知多得多，所以找到了一个别人都看不到的投资机会。或者，对自媒体写作和推广懂的多得多，并且利用这个认知的差异创办了很好的公号并受益颇多。这些有本质区别吗？你真的希望无视眼前经过的一个个机会，把自己的眼光聚焦到一个你可能都不是很清楚的点上，唯一的原因是这样做容易跳槽？
很多人经常吐槽这届领导不行，那次机会没赶上，公司都是剥削狂，用户鸡贼…… 但我要特别强调下，处理问题的方式是去【应对】，而非单纯的愤怒、焦虑、悲伤，然后什么也不做——这些东西除了让自己不爽，什么都改变不了，更谈不上成长了。
因此在做一份工作时，不管主管说什么（当然，遇到好的主管要开心一下，你的成长会大大加速），你要明确自己怎么才能成长。怎么才能利用这个企业给你的机会和资源去增长。这也是【从现实中学习】的真正意思。如果这个工作不利于你的长期增长，就离开。要留意，不是因为这里不让你学算法，而是无法帮你成长，你才离开。
那么话说回来，很多人都懂的算法也好，业务需求的各种细节也好，同事勾心斗角的小心思也好，它们是个人成长的一部分吗？什么是“大道”，什么是“奇技淫巧”？
好好想想吧。如果看不懂我在说啥，就当我在胡说八道吧。

4:既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？
简单来说，private并不是解决“安全”问题的。
安全是指不让代码被非法看到/访问。但是只要人能拿到代码，总会有办法去查看和改变代码。其他答案提到反射可以用SecurityManager来防止private被访问。但是从更高一层的角度，即便使用了SecurityManager，还是可以通过各种方式拿到java的bytecode，并做任意修改。比如有asm这样的lib，也有instrument api这种东西可以帮你。所以记得，如果你真有一段代码不允许被别人看/用，就不要把这段代码放到其他人可以碰到的地方，而是做一个server，通过接口允许有限制的访问。其他人想破解，只能破解你的服务器网关和跳板机器。
关于真正的安全性，可以参考激活服务器的工作原理
private想表达的不是“安全性”的意思，而是OOP的
概念，是一种编译器可以帮助你的设计上的hint。这就像是一家没人的店挂了个牌子“闲人免进”，但你真要进去还是有各种办法可以办到。所以private，以及所有其他的access modifier都有一层隐含的含义：如果你按照遵守这套规则，开发者可以保证不问题（不考虑bug的情况下）；否则，后果自负。
比如，你在用spring的IoC的时候，你知道你要“注入”，不管它是不是private的，你知道“注入”是你自己控制的，是你设计好的效果。那么通过spring的IoC利用反射帮你注入一些private property是再正常不过的用法。
再比如，单元测试，你就想测一个private方法。但是因为private的缘故就是测不了。于是你可以用反射绕开这个限制，开心的做测试。
虽说某些人坚持“不应该测试private方法，而应该通过测试其他方法间接测试private方法，但并没有形成广泛的共识。这里不对这个问题展开。
虽然能绕开，但绕开的代码很繁琐。久而久之就会厌倦。毕竟，
。因此，我的经验是通常会用protected或者default来代替private。我曾设想runtime应该给一种运行模式，通过设定一个启动参数使其不管private这类的限制，这样做UT，做profiling等工作都会轻松许多。等到最后发布时，再用普通模式。但可惜现实当中并没有这种设定。
评论区提到了Android里的
，可以实现我期望的功能。大赞！感谢 
 
我之所以敢用protected/default来代替private是因为现实当中非private不可的情景非常少见。实际上，很多时候private带来的麻烦比起带来的好处要多，这是因为很多时候对OOP的误用造成的。OOP的误用造成了无谓的private，然后逼着你必须得绕开private。
其实private就是个约定而已。看看其他语言，比如python，它的“private“是一种很松散的约定，所有private的成员都用下划线开头，告诉调用者“不要随便调用我哦”，但是如果真调用了也就调用了。C++，通过指针就能绕开private。有人说，private会避免新手误用。但问题是，大家从出道开始，自己或者周围的同事朋友有谁曾经出过这个问题？IDE知道一个成员当前不能访问，就根本就不会提示。如果一个人已经开始通过源代码/反编译研究“我能不能调用这个私有方法了“，他还算是一个菜鸟吗？他会不知道这里的潜在风险吗？如果真的误用了，code review能过吗？测试能过吗？如果一个公司因为误用private成员，造成了重大的损失，那这个公司就活该倒闭算了，不要在世上丢人。
OOP是一种编程思想，是众多编程思想中的一种。
如果抱着这种态度，就不会误用，因为private在开发者的心中。其他人也不太可能误用，如果他上过几天java培训。不要因为语言是OOP的就去套，把不适合的OOP的代码强用OOP的各种套路实现，然后给自己后续的维护扩展埋坑。

5:为什么数据库和数据库连接池不采用类似java nio的IO多路复用技术使用一个连接来维护和数据库的数据交换？
这是一个非常好的问题。IO多路复用被视为是非常好的性能助力器。但是一般我们在使用DB时，还是经常性采用c3p0，tomcat connection pool等技术来与DB连接，哪怕整个程序已经变成以Netty为核心。这到底是为什么？
首先纠正一个常见的误解。IO多路复用听上去好像是多个数据可以共享一个IO（socket连接），实际上并非如此。
。在网络服务中，IO多路复用起的作用是
。至于这些事件的处理方式，到底是业务代码循环着处理、丢到队列里，还是交给线程池处理，由业务代码决定。
对于使用DB的程序来讲，不管使用多路复用，还是连接池，都要维护一组网络连接，支持并发的查询。
为什么并发查询一定要使用多个连接才能完成呢？因为DB一般是使用连接作为Session管理的基本单元。在一个连接中，SQL语句的执行必须是串行、同步的。这是由于对于每一个Session，DB都要维护一组状态来支持查询，比如事务隔离级别，当前Session的变量等。只有单Session内串行执行，才能维护查询的正确性（试想一下一组sql在不断的增减变量，然后这组sql乱序执行会发生什么）。维护这些状态需要耗费内存，同时也会消耗CPU和磁盘IO。这样，限制对DB的连接数，就是在限制对DB资源的消耗。
因此，对DB来说，关键是要限制连接的数目。这个要求无论是DB连接池还是NIO的连接管理都能做到。
这样问题就绕回来了，为什么DB连接不能放到IO多路复用里一并执行吗？为啥大家都用连接池？
答案是，可以用IO多路复用——但是
。JDBC是一个出现了近20年的标准，它的设计核心是BIO（因为199X年时还没有别的IO可以用）：调用者在通过JDBC时执行比如query这样的API，在没有执行完成之前，整个调用线程被卡住。而类似于Mysql Connector/J这样的driver完备的实现了这套语义。
当然如果DB Client的协议的连接处理和解析稍微改一下：
就可以实现用IO多路复用来访问DB。实际上很多其他语言/框架里都是这么干的。比如Nodejs，see 
；或者Vert.X 的db客户端（
，不要在意这个名字，它实际上同时支持mysql和postgres）。只不过对于IO多路复用，数据库官方似乎都没做这种支持——他们只支持JDBC、ODBC等等这些标准协议。
那么为什么基于IO多路复用的实现不能成为默认的，官方的，而要成为偏门呢？
对于数据库开发者来说。这种用法在整体的用户里占有量非常小，所以也许不值当的花大力气。只需要把协议写清楚（比如
），就可以做实现。那么社区的有兴趣的人自然就可以去做。
另外一个原因是体系的支持。简单来讲，如果没有一个大的Reactive的运行环境，IO多路复用的使用会非常受限。
IO多路复用之所以能成立，是需要
——就是select的那句调用都。整个程序必须以这个驱动代码为核心。这样就对整个代码的结构产生重大的影响。这种影响是没法用简单的接口抽象的。
Java Web容器之所以可以使用NIO是因为NIO可以被封装到容器内部。Web容器对外暴露的还是传统的多线程形式的Java EE接口。
如果DB和Web容器同时使用NIO，那么调用的DB连接库与必须与容器有一个约定描述
。在Java这个大环境下，不同人，不同的容器写的代码不同；又或者，不使用任何常见的容器，而是自己用NIO去封装一个。这样是无法形成代码上的约定的。那么多个独立的组件就不能很好的共享NIO的驱动代码。
上面这个用法假设整个程序应该共享一个NIO驱动代码。那么Web和DB可不可以各用各的呢？也是可以的，但是为了保证这两个NIO驱动代码不会相互block，最好要分开两个线程。这样一来就会打破一般Web服务一个请求处理用一个线程的一般做法，会让程序边的更复杂——你的业务代码和DB查询之间必须做跨线程数据交换。
相反，连接池的实现就相对独立的多，也简单的多。外界只要配好DB URL，用户名密码和连接池的容量参数，就可以做到自行管理连接。
而Nodejs和Vert.X是完全不同的。他们本质就是Reactive的。他们的NIO的驱动方式是其运行时的基础——所有要在这个基础上开发的代码都必须遵守同样的NIO+异步开发规范，使用同一个NIO的驱动。这样DB与NIO的协作就不成问题了。
最后，
。批处理数据分析代码都是这样的场景。这样的程序写成NIO就会得不偿失——代码不容易懂，也没有任何效率上的优势。类似于Nodejs这样的运行时在此场景下，反而要利用
或等价的语法来让代码看起来是同步的，这样才容易写。
总结一下。DB访问一般采用连接池这种现象是生态造成的。历史上的BIO+连接池的做法经过多年的发展，已经解决了主要的问题。在Java的大环境下，这个方案是非常靠谱的，成熟的。而基于IO多路复用的方式尽管在性能上可能有优势，但是其对整个程序的代码结构要求过多，过于复杂。当然，如果有特定的需要，希望使用IO多路复用管理DB连接，是完全可行的。

6:为什么一定要弄一个Builder内部类？
不一定啊～
使用Builder大概有两个用途
下面分别说说两个用途。
Java支持使用constructor初始化一个object，但是如果object的成员非常多，constructor就不好用了。巨长的参数列表很难分清楚哪个是哪个。这时最好用某种方式让哪个字段是哪个更加清晰一点。Builder模式算是可以解决这个问题。此外题主在题目中那种让setter返回this的形式也可以解决。并且，能用"."连接下来配合IDE的自动提示还能够提高编码速度，这算是一个额外的便利。
插播一下这种返回this的setter并不符合java bean的setter规范。但一般来讲，严格遵守这个规范的意义不大。
构造函数不够好用是Java语法的一个根本性问题。有其他语言对此有更好的语法支持，比如kotlin，本来就支持用key=value的形式初始化一个object：
再比如javascript完全可以用object literal这样做。
尽管如此，不使用Builder，直接使用setter可能会得到一个状态不完整的object。这就是第二点作用。也是题主写法解决不了的。
如果追一下oop设计的本源，一个object从出生开始到被销毁，应该始终维护一种“不变量“（invariant），或者叫做始终处于valid状态。
比如，设计了一个Rectangle类，有两个字段width和height。为了让object的状态始终valid，我要求width和height必须都是正数，并且width与height之积不得超过100。假设class的定义是这样的：
如果要用setter初始化的话，那么object就会在完全被set好之前处于“invalid”的状态。
为了避免这种invalid状态的发生，就要求使用构造函数一次性初始化好所有的成员。但是如果是一个很多成员的class，构造函数不好用，那么唯一合理的办法就是做一个builder。这样builder就可以分多步初始化所有成员，build的结果出来就是一个处于valid状态的object。
当然，这个事情并不一定要这么解决，比如如果业务允许，你可以给Rectangle的成员设置合理的初始值，然后再用setter改，像这样：
有一类很特别的object就是“不可变object”。不可变是个很好的避免程序出问题的方法。具体“为什么不可变是一件好事情”的原因这里不展开了。为了得到一个不可变的object，是不可能使用任何setter方法的，必须使用构造函数一上来就把所有数据都设置好。因为多参数构造函数不好用，所以这里就得靠builder。
java对于final成员的要求是最晚构造函数得初始化，否则编译报错。这在有些时候不太好用。我们可能希望某个字段在第一次设置后就可以保持不变了。kotlin有个lazyinit的保留字实现了这个特性。
此外，上面这一坨代码就是Builder模式的正规写法，非常的繁琐。好在有Lombok的@Builder帮忙自动生成，不需要手写。
此外，也许你并不在意对象一直处于valid状态，只要在真正使用成员干活之前确保valid就行。那么就直接在干活前加判断是否valid就好。
如果这样做都不够灵活，你甚至都可以做一个public isValid()的方法让外界在调用关键动作之前，手动先验证Object的状态是valid。
还有一大类Object其实是“Data Object”，即用来做数据结构的。比如函数间传递一些参数，从接口或者数据库读出来的数据要有个存的地方等。这类Object压根就没什么“valid状态”一说，或者说，其是否合法完全是看业务场景的上下文，难以仅通过Object里数据本身就能判定的。对于这类object，直接用java bean规范new一个出来，然后挨个set就好。或者，按照我的想法，setter都是多余的，全部public成员直接赋值就足够了。
注意区分Data Object和面向对象里的那个Object，它们本质上是不同的东西
总结一下，如果你用Java，并且：
那么你需要一个builder。至于是不是内部类我觉得都可以。也许内部类会让人觉得“XXX.Builder属于XXX“，感觉上好些。
但是做了Builder后，还要做些额外工作告诉类的使用者“你应该用builder来创建object，而不是直接new“，这需要一些沟通、文档之类的工作量。
反之，如果：
那八成就不太需要做个builder。题主的写法也许已经足够好了。
对于一些语言，如kotlin，javascript，scala，python等，因为他们的语法本身就能支持builder的功能，基本上也就不需要手工实现builder了。

7:Spring是否代表着目前Java技术的顶峰，未来的Java将如何发展？
我感觉题主大概是对“什么是技术顶峰“的理解有点偏。
Spring使用场景的确非常普遍，大量公司都在用Spring搭建自己的服务系统，因为好学，好招人，已经被业界证明非仓靠谱。但非得要说“用的广泛”就“顶峰”了，怪怪的。比如大部分人都要住房，但如果非得说“盖房子”是人类工程技术的顶峰，听上去是不是怎么都不太对劲？只不过当一个人连房子都住不起时，追求住房子天经地义而已。
如果我们把顶峰定义为于形成了某种“壁垒”，其他技术做不到或者做不好，可能更合适一点。尽管Spring可以做依赖注入，实现web，做接口，实现微服务，方便访问数据…… 但这些功能Java其他的工具也可以做，非Java领域的也能做（没准做得更好），道理上也没那么难理解。对于大量没有技术深入积累的公司或组织，用Java实现业务需求，Spring是个不差的选择。Spring覆盖了常规业务开发几乎所有的方面，也非常值得学习。
如果非要挑几个Java世界里的“顶峰”级别的项目，我会考虑下面几个（注意这里会把JVM本身和Scala等JVM衍生语言也算在内）：

8:IO多路复用和线程池哪个效率更高，更有优势？
问题本身貌似有问题。简单比较两种工具的优劣意义不大。你没法说锤子和剪刀那个更好。我们一般会评价对于某个场景，哪种工具更合适。
io多路复用（这翻译真的很坑爹啊），指的是同一个进（线）程可以处理多个IO数据流。
多线程+池模型指的是每个线程处理一个IO流。
IO多路复用的优势在于，当处理的消耗对比IO几乎可以忽略不计时，可以处理大量的并发IO，而不用消耗太多CPU/内存。这就像是一个工作很高效的人，手上一个todo list，他高效的依次处理每个任务。这比每个任务单独安排一个人要节省（雇人是要发工资的……）。典型的例子是nginx做代理，代理的转发逻辑相对比较简单直接，那么IO多路复用很适合。相反，如果是一个做复杂计算的场景，计算本身可能是个 指数复杂度的东西，IO不是瓶颈。那么怎么充分利用CPU或者显卡的核心多干活才是关键。
此外，IO多路复用适合处理很多闲置的IO，因为IO socket的数量的增加并不会带来进（线）程数的增加，也就不会带来stack内存，内核对象，切换时间的损耗。因此像长链接做通知的场景非常适合。
IO多路复用 + 单进（线）程有个额外的好处，就不会有并发编程的各种坑问题，比如在nginx里，redis里，编程实现都会很简单很多。编程中处理并发冲突和一致性，原子性问题真的是很难，极易出错。
但是现实中，也有IO多路复用 + 多worker线程的做法，这样上面这个好处就没有了。
如果做不到“处理过程相对于IO可以忽略不计”，IO多路复用的并不一定比线程池方案更好。比如一个web的服务，用jetty 9的NIO connector，后边是spring svc + JDBC连接数据库。spring svc + JDBC连接数据库这两块的处理延迟相对于NIO来说不能忽略，所以并不能指望用jetty 9的NIO connector换了之前的BIO connector的容器，性能能高不少（实际上应该会高一些，但不会太夸张，毕竟瓶颈在后边处理和DB上）。
顺便提一句，Java世界里，因为JDBC这个东西是BIO的，所以在我们常见的Java服务里没有办法做到全部NIO化，必须得弄成多线程模型。如果要在做Java web服务这个大场景下享受IO多路复用的好处，要不就是不需要DB的，要不就是得用Vert.X一类的纯NIO框架把DB IO访问也得框进来。
最后，如果IO压力过大，一个高并发的东西和一个不那么高并发的东西，都不能正确响应，对用户来说是一样的——
。假如IO非常的繁重，没有空闲的连接，那么IO的压力在两种模型下表现差不多，IO多路复用的“并发“看了起来会大一些，但因为IO已经满了，所以表现出超时严重；而线程池可能表现为，所有的线程都因为IO过慢而卡死了，线程池耗尽，新的请求进不来直接报错。但不管哪一种，在极端压力下，都无法正常工作。这时，要想着怎么扩容。
简单总结一下，

9:cas做了锁了总线或缓存行还是volatile做了锁总线或缓存行?
谢邀。
这个问题分为2层：
首先看一下手册的原文，见
文档中说的很清楚，对于Lock指令区分两种实现方法
对于早期的CPU，总是采用的是锁总线的方式。具体方法是，一旦遇到了Lock指令，就由仲裁器选择一个核心独占总线。其余的CPU核心不能再通过总线与内存通讯。从而达到“原子性”的目的。
具体做法是，某一个核心触发总线的“Lock#”那根线，让总线仲裁器工作，把总线完全分给某个核心。
这种方式的确能解决问题，但是非常不高效。为了个原子性结果搞得其他CPU都不能干活了。因此从Intel P6 CPU开始就做了一个优化，改用Ringbus + MESI协议，也就是文档里说的cache conherence机制。这种技术被Intel称为“Cache Locking”。
根据文档原文：如果是P6后的CPU，并且数据已经被CPU缓存了，并且是要写回到主存的，则可以用cache locking处理问题。
。因此，lock到底用锁总线，还是用cache locking，完全是看当时的情况。当然能用后者的就肯定用后者。
Intel P6是Intel第6代架构的CPU，其实也很老了，差不多1995年出的…… 比如Pentium Pro，Pentium II，Pentium III都隶属于P6架构。
MESI大致的意思是：若干个CPU核心通过ringbus连到一起。每个核心都维护自己的Cache的状态。如果对于同一份内存数据在多个核里都有cache，则状态都为S（shared）。一旦有一核心改了这个数据（状态变成了M），其他核心就能瞬间通过ringbus感知到这个修改，从而把自己的cache状态变成I（Invalid），并且从标记为M的cache中读过来。同时，这个数据会被原子的写回到主存。最终，cache的状态又会变为S。
这相当于给cache本身单独做了一套总线（要不怎么叫ring bus），避免了真的锁总线。
回到CAS。
我们一般说的CAS在x86的大概写法是
对于一致性来讲，“lock”前缀是起关键作用的指令。而cmpxchg是一个原子执行“load”，“比较”，“save“的操作。Intel规定lock只能对单条指令起作用。我不是很清楚为啥Intel是这么设计的，比如必须要lock和cmpxchg一起写。有没有可能cmpxchg可以单独用的时候？也许是单核处理器的时候可以不用lock了？哪位知道麻烦留个评论。
CAS的特性使得他称为实现任何高层“锁”的必要的构建。几乎所有的“锁”，如Mutex，ReentrantLock等都得用CAS让线程先原子性的抢到一个东西（比如一个队列的头部），然后才能维护其他锁相关的数据。并且很有意思的是，如果一个竞争算法只用到了CAS，却没有让线程“等待”，就会被称为“无锁算法”。CPU会不会有点小郁闷……
----------------------------
根据评论区更新一下。
。
实际上CAS和cmpxchg压根就没处理过ABA问题。严格来说CAS就不会有ABA的问题，它只是一个简单的，原子的"比较-设置值"的指令而已。
会出ABA问题的是这种CAS的用法：
即这个代码的第一句和第三句可能看到的curVal是一样的，但是有可能造这个curVal在另一个线程ABA了。
如果真的需要解决ABA问题，需要上层代码来处理，比如
BTW，现实工程当中，绝大部分情况下，都不需要考虑ABA问题。
CPU锁和应用层的锁要解决的问题不一样。
CPU锁主要解决的是多个核心并发访问/修改同一块内存的问题。所以有锁总线和MESI协议来做。对于上层主要的抽象就是CAS。主要的招数就是用CAS+循环来抢东西。如果抢不到就只能
应用层的锁存在了“进程/线程“的概念（下文统一都说进程）。解决的是多个进程并发访问同一块内存的问题。比起CPU的层级来说，应用层的锁可以多一个招数，叫做“让给让前进程不可调度“。这个是OS提供的支持。
因此在应用层的层次上你可以定义一个高级的“锁”，大概执行这样一个抢锁流程
而当某个进程释放锁时，他就可以做释放锁的流程
简单来说，
。

10:为什么说java spi破坏双亲委派模型？
虽然有SPI破坏双亲委派模型的说法，但我不太认同。简单说下。
双亲委派模型（再次吐槽下这个翻译），是一种加载类的约定。这个约定的一个用处是保证安全。比如说你写Java用了String类，你怎么保证你用的那个String类就是JDK里提供的那个String类呢？答案是对于JDK基础类，JDK要用特殊的ClassLoader来保证在正确的位置加载。JDK主要有3个自带ClassLoader：
双亲委派模型要求如果一个类可以被委派最基础的ClassLoader加载，就不能让高层的ClassLoader加载。这样你就知道你用的String类一定是被BootstrapClasserLoader加载的/lib下的那个rt.jar的那个java/lang/String.class.
但
。如果你自己写个自己的ClassLoader，你可以不理会它。比如你可以写个自己的ClassLoader去自己规定的一个神怪的目录里加载自己写的String.class。当然Java Runtime能够识别出这俩String不是一个类，哪怕他们的Full Qualified Class Name一模一样。所以如果你这做了，大概率是自作自受。当如果你真的知道自己在干啥，是能够玩出一些花的。
顺便说一句，这个机制的安全性是有限的。假如有人能登入服务器，能够直接替换JDK目录的文件。上述机制也就失效了。为了保证严格的安全，还应该保证系统文件要做数字签名。
另外一点是，这个模式虽然“安全“，但是损失了一丢丢灵活性。就比如java.sql.Driver这个东西。JDK只能提供一个规范接口，而不能提供实现。提供实现的是实际的数据库提供商。提供商的库总不能放JDK目录里吧。
Java从1.6搞出了SPI就是为了优雅的解决这类问题——JDK提供接口，供应商提供服务。编程人员编码时面向接口编程，然后JDK能够自动找到合适的实现，岂不是很爽？
但是便利的同时也带来了困扰。提供商提供的类不能放JDK里的lib目录下，所以也就没法用BootstrapClassLoader加载了。所以当你代码写了
时，这个代码会用Bootstrap ClassLoader尝试去加载.问题是java.sql.Driver是个接口，无法真的实例化，就报错了。
没有SPI时，你可以现在classpath里加一个mysql-connector-java.jar，然后这样写
这就没问题了，这里用了Application Classloader加载了mysql-connector-java.jar的com.mysql.jdbc.Driver。问题是你hard code了一定要加载"com.mysql.jdbc.Driver"，不是很优雅，不能实现“用接口编程，自动实例化真的实现“的这种编码形式。
使用SPI后，代码大致会这样
DriverManager就根据"jdbc:mysql"这个提示去找具体实现去了。
然后
就会看到这里的结果是Application ClassLoader。这就好像Application ClassLoader加载了本来应该由BootstrapClassLoader加载的java.sql.Connection一样。看起来像是违反了双亲委派模型。但实际上，这里的Connection的类型实际上是“com.mysql.jdbc.JDBC4Connection“，也是个第三方类。AppClassLoader加载一个第三方类看起来并没有违反模型。
再进一步调查下Connection接口自己的加载情况：
会发现返回的null。说明Connection自己是被Bootstrap ClassLoader加载的。
综上，并没有说Bootstrap ClassLoader加载了个第三方库或者Application ClassLoader加载了JDK的库的情况发生。
所以能否请题主给出具体哪里写了“SPI破坏双亲委派模型“？我再仔细看看是不是前后哪里谁理解错了。可能是我错了，也可能是那个参考错了。

11:为何谷歌之类大厂程序员认为敏捷开发是瞎扯淡？
天天用敏捷开发（其实很多时候实际上是“混沌开发”），习惯成自然，自然变信仰的同时，不要忘记了：
总之，要解决的问题用敏捷有效就用，用敏捷不好就换更适合的。犯不着上纲上线。

12:数据库MVCC和隔离级别的关系是什么？
谢邀。
首先我要指出问题中提出的各种概念非常混乱。简单梳理下：
早期数据库不论读取还是写入，都用锁来实现。但是锁会带来性能的问题。人们尝试各种优化方案。写入和读取的优化方式不同。
对于数据库写入操作，没有特别好的办法，因为无论如何要避免并发修改一个数据，就得靠锁。不同的数据库对于写入操作都会加悲观锁（比如MySQL是X锁）。为了避免X锁带来的性能问题，人们在合适的场合会选择用乐观锁来优化。有的数据库内建乐观锁，但是有的没有（比如MySQL就没有），所以需要开发人员自己在数据表里加version列，自己写业务代码实现。
顺便提一句，乐观锁并不一定总是比悲观锁性能表现更好，这要看竞争的程度。如果数据访问竞争的非常厉害，乐观锁只会让CPU和IO白白浪费而已。
对于读取，优化就是MVCC。现在主流的商业数据库都是基于MVCC，如MySQL InnoDB和Postgres。MVCC的意思用简单的话讲就是
。这样读某一个数据时，事务可以根据隔离级别选择要读取哪个版本的数据。过程中完全不需要加锁。
这样，实现两个隔离级别就非常容易：
举个简单的例子：
注意，这里B不论是Read Committed，还是Repeatable Read，都不会被锁，都能立刻拿到结果。这也就是MVCC存在的意义。
在基于MVCC的数据库实现中，根本就不需要出现Read Uncommitted这种情况。Read Uncommitted是早期数据库，读写都基于锁进行实现的产物。在实际业务中Read Uncommitted毫无意义（如果真有意义，你咋不去用NoSQL数据库？）因此：
所以从实际的角度出发，我想所有人都忘记有“Read Uncommitted”这件事。
MVCC并不是万灵药。大量的业务问题的关键点在于，
。对于这种场景，无论是Read Committed还是Repeatable Read都没有什么卵用。比如扣库存就是这样典型的业务场景。
在这种场景下
希望上面的简单回答可以让你重新对数据库、锁和隔离级别有所认识。如果没看懂也不奇怪，问题本身的确非常复杂，所以我专门写了一篇很长的文字来解释这个问题，希望可以帮到你。

13:微服务架构中如何解决连表查询的问题？
先区分好是OLAP还是OLTP。
对于OLAP还是要联表查询，但查询的不是线上数据库，而是经过ETL或者某种清洗过的数据仓库。比如都导入到一个Greenplum里，或者用presto这种聚合层来远程联表。对于更大数据量，需要清洗到HBase这样的海量数据库中用Hive、Spark等工具做分析（这时也不是常规意义上的表了）。当然，OLAP了嘛，数据就不那么即时，数秒～数个小时的延迟都可能发生，报表够用就好。
对于OLTP，比如前端要展示订单列表，订单列表里需要同时展示用户的信息。这就需要所谓“application join”。大概的做法是：
这种做法有几个要求：
因为有这些限制，还得手写join代码，开发者会付出许多额外工作量。因此在OLTP中，并不是任何数据之间都随便join的。一般都是一个业务数据和用户信息这种公共数据之间join。微服务拆分时也偏向于把用户数据这样的服务独立出来。
还有一种完全不同的做法是采用Event-sourcing，即不是将“数据表”作为数据源，而是把不可变的数据流作为数据源（比如存在kafka里），每一个微服务私有的数据表都是数据源转换得到的的“视图”或者“查询索引”。在这种设计模式下，每个微服务可能会维护自己的专有的“用户数据表“。这个微服务去监听数据流中用户注册和用户信息修改的message，并把自己感兴趣的数据记录下来。一个用户的完整信息可能有几十上百个字段，但每个微服务只关心和自己相关的那几列。多个服务都可以维护自己的“用户数据”，做自己的用户信息处理和清晰，满足自己的查询需要。
这样做的好处是系统之间从数据上都彻底解耦。每个微服务可以用自己最适合的方式存储数据，如可以存到rocksdb，redis，elastic search，hbase等；也可以做各种各种加工，做成特定的数据结构（KV，树，图，倒排索引，空间索引……）。坏处是存储会冗余（但存储相对便宜还相对容易被接受）；以及Effective Once Message Processing（EOMP）的引入。系统必须保证每个message必须只能处理一次，不能多也不能丢，否则数据正确性会被损坏。比如订单微服务中因为系统偶尔抽疯，少处理和记录一个用户的数据。但那个用户在用户微服务中明明是存在的。这又变相的要求了高性能+高可用的message replay和total order broadcast以及幂等。这几个主题目前都相对难搞一些，需要特别的的工具、监控和人才才能搞得定。
关于这个思想可以参考：
但话说回来，拆分为微服务
都会带来分布式事务写入的问题。Event-sourcing是一种分布式事务的处理方法（区别于XA那种）。如果不搞分布式事务就面临最终一致性的大坑。最终一致性最麻烦的就是不满足Linearizability带来的无穷无尽的、反直觉的bug。有人戏称“最终一致性最终得到了不一致“。如果业务上对最终一致性带来的“最终不一致”的后果不能忍，还是得多考虑分布式一致性。之前我回答过一个问题可以看下：
最后，最最屎的做法就是服务拆了，但是数据表混着公用。我希望这是最后一招，在没有办法的时候才用的最后的办法。比如拆了微服务，但是项目有压力，马上就要上线，一个OLTP的API必须得join才能得到那个数据。这样做了也要考虑“怎么把这个join给干掉”，否则后患无穷。不要给自己和后续维护的同事挖坟哈。

14:JAVA面试经常会被问题 JVM调优？
谢邀。
一般面试时问JVM调优，主要是因为，这个技术并不是懂了Java就能自然懂的，需要明白一些底层原理，有一些深度。所以比较适合用来查看面试者是不是足够“高级”。
那么面试时，如何回答JVM调优？主要需要你能回答两方面的问题：
在面试中可以先从一个具体的问题开始讨论你的做法，从猜测，到运用工具观察，到找到问题所在，最终提出方案。当然前提是你的确熟悉这些内容。如果在实际工作中真的没尝试过，可以看看这本书《
》混个脸熟。这本书里有数个调优的例子，值得参考。
希望有帮助。

15:为什么只有Java多线程有可见性问题？
显然不是的。只要直接采用了多线程的并发模型，并采用共享内存的方式作为数据的通讯方式，就一定有可见性问题。这种问题Java有，C有，C++有，C#也有。这几门语言都有对应的方式解决这个问题。
C#的volatile基本上和Java差不多；
C和C++尽管有volatile关键字，但他们并不是针对多线程的数据可见性设计的。它们的意思仅仅是避免编译器优化（比如reorder）代码，但是并不保证寄存器和主存的一致性。但他们也得解决多线程下可见性问题，具体的办法是利用某些fence函数或者指令。这些办法在不同平台的编译器不太一样。
感谢 评论区 @李宁 指正。
举其他几个例子。
比如javascript的用户线程就1个（nodejs或者浏览器，不算service worker/cluster），完全用异步解决任何问题。所以不会有可见性问题。
再比如go用channel作为多个goroutine的通讯方式，channel这个东西从抽象层面就杜绝了不可见问题。你可以大概理解为但凡塞进channel的数据都被“volatile”了一下。但go也允许多个goroutine不使用channel，直接使用共享内存的方式来通讯。go社区不建议这么做，但如果你真的这么干的时候，需要sync包来帮你搞同步（同步了就自然可见了），或者link C/C++代码上。go里没有volatile的直接支持。
Python支持半残的多线程（特指CPython，而不是同时泛指IronPython，JPython等）。GIL的存在貌似天然的规避了可见性的问题，但是除非有IO wait，Python压根就没真的利用多线程实现并发。因此Python对并发问题的处理是用“多进程”，而不是“多线程“。Ruby应该类似，同样的半残多线程，同样的GIL。Ruby对于并发任务一般用sidekiq/resque + 多worker进程的方式。（不知道有没有Ruby专家出来讲讲）。
Objective C、Swift的并发模型都使用GCD，而不是自己搞多线程。这个有点像go的感觉。苹果做运行时很早就意识到了多线程非常危险的问题。
我看了很多语言，发现Java貌似是比较早的把多线程模型做的非常好用的语言。这里的“非常好”是指，用户用起来方便，同步、锁、volatile、threadLocal一应俱全，之后的JUC更加的强大。但是也正因为“太好用了”，却起了反效果，很多人以为自己会了多线程就开始写出了很多并不安全，有大坑的代码。volatile就是个典型的例子。它问题是抽象层次太低，能解决问题的面太窄，也不容易用对。很多人搞不清什么时候可见性就足够了，什么时候必须同步。
实际上整个直接用线程 + 同步的方式的并发模型都太容易出错了，体现在：
就算你管得住自己的代码，写的是对的，你也无法确保自己的代码不能成为其他代码的一部分，更无法保证整体是正确的。因此，除非是做底层开发的，尽量用高层包装好的并发同步工具。对于类似于volatile，如果非得用它的特性，最好用JUC的AtomXXX的类。

16:数据库事务原子性、一致性是怎样实现的？
ACID的关系很微妙，并不正交。有人戏称“ACID”完全是为了凑这个缩写。
先说C。C代表“正确性”。这个C与主从复制的C，CAP里的C都不太一样。从总体上AID一起带来了C。如果数据被改了一半（不满足A），互相干扰（I不满足），挂了后丢数据（D不满足），就肯定不可能说数据是正确的。
但因为存在end 2 end argument，实际上应用代码也该被考虑为支持C的一个必要因素。所以可以理解为“
“。
A代表着“可rollback“，目前主要有两类方案：
I让并发事务执行时互不干扰的执行。其实这就等价于这些事务以某个Serial的顺序跑。只不过大家在实际用的时候为了提高吞吐，会用“弱一点点”的隔离。所以才有Read Committed这类“弱一点”的级别。用弱隔离级就必然“不那么隔离”，就无法避免Read Skew，Lost Updates和Write Skew这类问题。如果业务能忍当然好，如果不能忍就还得上Serialization。比如任何具有read-process-write结构的逻辑使用弱隔离级别都可能出错。此时可以用Serialization隔离级别，也可以手工加锁强行Serialization。锁可以用悲观也可以用乐观。
D就是要持久化存储。持久化的关键有两点。第一个是“尽快落盘”。在写入核心数据结构之前，需要先写事务log。MySQL Innodb称为redo log。Postgres称为WAL。但意思都是一样的。即如果万一数据库挂了，重启恢复数据时，必须先从log里做“redo“。但为了吞吐，管理员是可以配置成每隔N个时间/N个事务刷盘一次，但这也就意味着一旦系统挂掉，就会丢掉这么多时间/个数的事务。
第二点是复制，对数据保留尽可能多的副本。在单机下通过挂磁盘阵列是可以实现的。但常规都会用多机器的副本。不然没法“failover”以应对机器挂掉的风险。
但使用副本后，如何保证副本之间的一致性也是大麻烦（这里的一致性和上面ACID的C不同，就指主和从数据是一样的）。因为除非主从可以同步（延迟一般不可接受），否则肯定双方会有瞬间不太一致的情况。为了保证让不一致可以最终变得一致，不会因为机器挂掉丢失数据，就得让主从复制这个流程3大步骤: copy-apply-record，能够做到exactly once。这又变相的需要对数据库内部数据实现AID的支持。
为了折腾一个复制，你会看到MySQL搞了一大把的机制才能勉强hold住这件事，包括sync_binlog, trx_commit, 半同步复制，binlog/redo log 2PC提交，组提交，crash-safe replication, ……
再多说一句，不同数据库对ACID的实现有很大的区别，对于同一个名词的含义也完全不同。（MySQL的Repeatable Read和Postgres完全不同）。学习时要把数据库理论和特定的数据库实现分开看。现代数据库的实现的复杂度已经远远超过普通教科书的理论。所以一定要拿具体数据库的手册和理论对照。
如果是MySQL的话我比较推荐这本书：
对于理论，还是推荐我最喜欢的DDIA。请反复阅读第5、6、7、8、9几章，直到背熟为止。

17:Kafka事务到底是什么意思？
Kafka的事务和数据库里用的ACID事务不是一个东西。
Kafka的事务主要用来
：一个数据处理服务从Kafka的若干源topic取数据，处理后，再发送到另外一些目标topic里。在这个过程中，Kafka事务保证：要么数据被处理了，目标topic的结果被正确写入，源topic的数据被消费掉；要么这个数据还能从源topic里读取到，就像没被处理过一样，不会出现源topic还没consume，目标topic已经produce出去的情况。并且，源和目标topic不止一个时也可以保证这个特性。
这个特性大概可以被看作是事件被处理了exactly once。当然，实际上处理可以做多次，但只要没写入到目标topic，就可以看作是没处理过。
这个保证其实很难实现，主要的论述在这里：
在kafka没有提供这种api之前，kafka用户只能基于at least once来设计自己的处理，比如自己实现幂等语义，自己记录最近一段时间哪个数据被处理过了等等。
messaging系统的exactly once delivery语义在理论上被认为是不可能的，可以看这里：
然而从业务上讲，总有可以近似的“exactly once”处理，并且能满足实际需要的方案。所以Kafka搞出了这个事务。那么既然exactly once delivery不可能，怎么又能做到呢？请特别留意“message exactly once delivery”和“message (almost) exactly once processing” 这两个意思细微的差别。
Kafka事务是Kafka Streams API的一部分。这就是说，如果你的处理代码的数据源和数据目的地不止是kafka的topic（比如DB，redis，HBase等），kafka事务并不能保证跨系统的exactly once。
但即便如此，有了这个事务的支持，Kafka的用户过得舒坦了些，confluent公司的营收也会更好吧。

18:Java 中的双亲委派的“双”怎么理解 ？
其实就是个翻译问题。
双亲委派的原文是"parents delegate"。parents在英文中是“父母”、“双亲”的意思，但其实表达的是“父母这一辈”的人的意思。实际上这个模型中，只是表达“父母这一辈”的class loader而已，并不是说真的有一个父亲的class loader和一个母亲class loader。
下面引用了Java API doc的原文，大家可以参考：
The Java platform uses a delegation model for loading classes.
When loading a class, a class loader first "delegates" the search for the class to its parent class loader before attempting to find the class itself.
见
其实OOP中也有所谓“parent class”的概念，但我们一般也只称为“父类”而已（难道就是因为没有那个复数s吗？）
P.S. 
对于本题中有些回答硬要给“双”找个含义，我只能表示由衷的呵呵。

19:使用redis做减库存、下单，如何保证这两步操作的要么都成功要么都失败?
请永远用支持ACID事务的数据库来处理下单这种场景。
redis的事务充其量只能保证I—isolation而已。
如果你不理解什么是ACID，可以看我这篇文章的开头部分: 
2018年3月20日更新
追加了一篇讨论redis使用方式的文章，

